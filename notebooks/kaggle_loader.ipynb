{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79fc9442",
   "metadata": {},
   "source": [
    "# Kaggle Data Loader - Databricks Notebook\n",
    "\n",
    "This notebook downloads Kaggle datasets and loads them to Databricks Volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kaggle pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fac663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option 1: Use Databricks Secrets (Recommended)\n",
    "try:\n",
    "    username = dbutils.secrets.get(\"kaggle-scope\", \"username\")\n",
    "    api_key = dbutils.secrets.get(\"kaggle-scope\", \"api-key\")\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = username\n",
    "    os.environ[\"KAGGLE_KEY\"] = api_key\n",
    "    print(\"✓ Kaggle credentials configured from secrets\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not load from secrets: {e}\")\n",
    "    print(\"Create secrets with: dbutils.secrets.create_scope('kaggle-scope')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8856a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Workspace/databricks\")\n",
    "\n",
    "from basics.file_read import DatabricksKaggleLoader\n",
    "\n",
    "print(\"✓ Module imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loader\n",
    "loader = DatabricksKaggleLoader(\n",
    "    databricks_path=\"/Volumes/workspace/default/kaggle\"\n",
    ")\n",
    "\n",
    "# Download and upload dataset\n",
    "print(\"Starting download from Kaggle...\")\n",
    "dataset_path = loader.download_and_upload_dataset(\n",
    "    dataset_name=\"aekundayo/health-insurance-data\",\n",
    "    file_name=\"BenefitsCostSharing.csv\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset uploaded to: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Verify dataset file exists before loading\n",
    "\n",
    "csv_path = f\"{dataset_path}/BenefitsCostSharing.csv\"\n",
    "\n",
    "# Check if file exists in Databricks Volumes\n",
    "try:\n",
    "    dbutils.fs.ls(csv_path)\n",
    "    print(f\"✓ File verified at: {csv_path}\")\n",
    "    \n",
    "    # Load CSV file\n",
    "    df = loader.load_csv_with_spark(csv_path, num_rows=10)\n",
    "    print(\"✓ Dataset loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ File not found or error loading: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "csv_path = f\"{dataset_path}/BenefitsCostSharing.csv\"\n",
    "df = loader.load_csv_with_spark(csv_path, num_rows=10)\n",
    "\n",
    "# Display dataframe\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics\n",
    "print(f\"Dataset shape: {df.count()} rows, {len(df.columns)} columns\")\n",
    "print(\"\\nColumn types:\")\n",
    "df.printSchema()\n",
    "print(\"\\nNull values per column:\")\n",
    "df.select([(F.count(F.when(F.col(c).isNull(), c))/F.count(F.lit(1))).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f125a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in Volumes\n",
    "import os\n",
    "print(\"Files in Databricks Volumes:\")\n",
    "dbutils.fs.ls(\"/Volumes/workspace/default/kaggle/health-insurance-data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
